{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리들만의 단어 사전 만들기\n",
    "# https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-29%EC%9D%BC%EC%B0%A8-spacy-%EC%86%8C%EA%B0%9C-1b76d1746c6c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (2.3.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: setuptools in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (49.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: colorama in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\n",
      "  Using cached en_core_web_sm-2.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: setuptools in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.2.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.26.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.62.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.7)\n",
      "Requirement already satisfied: colorama in d:\\git\\study\\nltk\\nltk\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.4)\n",
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\git\\study\\nltk\\nltk\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_16192/2779271299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Git\\study\\nltk\\nltk\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Git\\study\\nltk\\nltk\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'I always uh do the main um processing, I mean, the uh um data-processing.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = nlp(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(I always uh do the main um processing, I mean, the uh um data-processing.,\n",
       " spacy.tokens.doc.Doc)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats, type(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I <class 'str'>\n",
      "always <class 'str'>\n",
      "uh <class 'str'>\n",
      "do <class 'str'>\n",
      "the <class 'str'>\n",
      "main <class 'str'>\n",
      "um <class 'str'>\n",
      "processing <class 'str'>\n",
      ", <class 'str'>\n",
      "I <class 'str'>\n",
      "mean <class 'str'>\n",
      ", <class 'str'>\n",
      "the <class 'str'>\n",
      "uh <class 'str'>\n",
      "um <class 'str'>\n",
      "data <class 'str'>\n",
      "- <class 'str'>\n",
      "processing <class 'str'>\n",
      ". <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for token in stats:\n",
    "    print(token.text, type(token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korea\n",
      "has\n",
      "a\n",
      "reasonable\n",
      "population\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc2 = \"Korea has a reasonable population.\"\n",
    "stats = nlp(doc2)\n",
    "for token in stats:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I always uh do the main um processing, I mean, the uh um data-processing.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korea\n",
      "has\n",
      "a\n",
      "reasonable\n",
      "population\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in stats:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "always\n",
      "uh\n",
      "do\n",
      "the\n",
      "main\n",
      "um\n",
      "processing\n",
      "I\n",
      "mean\n",
      "the\n",
      "uh\n",
      "um\n",
      "data\n",
      "processing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for token in re.split(\"\\W+\", doc):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "S\n",
      "A\n",
      "has\n",
      "a\n",
      "reasonable\n",
      "population\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "doc2 = \"U.S.A. has a reasonable population.\"\n",
    "for token in re.split(\"\\W+\", doc2):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S.A.\n",
      "has\n",
      "a\n",
      "reasonable\n",
      "population\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "stats = nlp(doc2)\n",
    "for token in stats:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "listVocabulary = list(nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180, list)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listVocabulary), type(listVocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\"', '#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listVocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^__^'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listVocabulary[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ph.d.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listVocabulary[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>terrible place to work for i just heard a stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>hours , minutes total time for an extremely s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my less than stellar review is for service . w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m granting one star because there s no way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>the food here is mediocre at best . i went aft...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating                                             review\n",
       "0  negative  terrible place to work for i just heard a stor...\n",
       "1  negative   hours , minutes total time for an extremely s...\n",
       "2  negative  my less than stellar review is for service . w...\n",
       "3  negative  i m granting one star because there s no way t...\n",
       "4  negative  the food here is mediocre at best . i went aft..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55995</th>\n",
       "      <td>positive</td>\n",
       "      <td>great food . wonderful , friendly service . i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55996</th>\n",
       "      <td>positive</td>\n",
       "      <td>charlotte should be the new standard for moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55997</th>\n",
       "      <td>positive</td>\n",
       "      <td>get the encore sandwich ! ! make sure to get i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55998</th>\n",
       "      <td>positive</td>\n",
       "      <td>i m a pretty big ice cream gelato fan . pretty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55999</th>\n",
       "      <td>positive</td>\n",
       "      <td>where else can you find all the parts and piec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review\n",
       "55995  positive  great food . wonderful , friendly service . i ...\n",
       "55996  positive  charlotte should be the new standard for moder...\n",
       "55997  positive  get the encore sandwich ! ! make sure to get i...\n",
       "55998  positive  i m a pretty big ice cream gelato fan . pretty...\n",
       "55999  positive  where else can you find all the parts and piec..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 사전 만들기 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeVocabulary():\n",
    "    unkToken = \"<UNK>\"\n",
    "    vocab['t_2_i'] = {}\n",
    "    vocab['i_2_t'] = {}\n",
    "    vocab[\"unkToken\"] = unkToken\n",
    "    idx = addToken(unkToken)\n",
    "    vocab[\"unkTokenIdx\"] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToken(token):\n",
    "    if token in vocab[\"t_2_i\"]:\n",
    "        idx = vocab[\"t_2_i\"][token]\n",
    "    else:\n",
    "        idx = len(vocab[\"t_2_i\"])\n",
    "        vocab[\"t_2_i\"][token] = idx\n",
    "        vocab[\"i_2_t\"][idx] = token\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addManyTokens(tokens):\n",
    "    idxes = [addToken(token) for token in tokens]\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpToken(token):\n",
    "    if vocab[\"unkTokenIdx\"] >= 0:\n",
    "        return vocab[\"t_2_i\"].get(token, vocab[\"unkTokenIdx\"])\n",
    "    else:\n",
    "        return vocab[\"t_2_i\"][token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpIndex(idx):\n",
    "    if idx not in vocab[\"i_2_t\"]:\n",
    "        raise KeyError(\"the index (%d) is not there\" % idx)\n",
    "    return vocab[\"i_2_t\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabularyFromDataFrame(df, cutoff = 25):\n",
    "    initializeVocabulary()\n",
    "    wordCounts = Counter()\n",
    "    for r in df.review:\n",
    "        for word in re.split(\"\\W+\", r):\n",
    "            wordCounts[word] += 1\n",
    "    for word, count in wordCounts.items():\n",
    "        if count > cutoff:\n",
    "            addToken(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularyFromDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t_2_i', 'i_2_t', 'unkToken', 'unkTokenIdx'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, dict, str, int)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab['t_2_i']), type(vocab['i_2_t']), type(vocab['unkToken']), type(vocab['unkTokenIdx']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<UNK>', 0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['unkToken'], vocab['unkTokenIdx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'terrible': 1,\n",
       " 'place': 2,\n",
       " 'to': 3,\n",
       " 'work': 4,\n",
       " 'for': 5,\n",
       " 'i': 6,\n",
       " 'just': 7,\n",
       " 'heard': 8,\n",
       " 'a': 9,\n",
       " 'story': 10,\n",
       " 'of': 11,\n",
       " 'them': 12,\n",
       " 'find': 13,\n",
       " 'girl': 14,\n",
       " 'over': 15,\n",
       " 'her': 16,\n",
       " 'father': 17,\n",
       " 'coming': 18,\n",
       " 'in': 19,\n",
       " 'there': 20,\n",
       " 'who': 21,\n",
       " 'she': 22,\n",
       " 'hadn': 23,\n",
       " 't': 24,\n",
       " 'seen': 25,\n",
       " 'years': 26,\n",
       " 'said': 27,\n",
       " 'hi': 28,\n",
       " 'him': 29,\n",
       " 'which': 30,\n",
       " 'upset': 31,\n",
       " 'his': 32,\n",
       " 'wife': 33,\n",
       " 'and': 34,\n",
       " 'they': 35,\n",
       " 'left': 36,\n",
       " 'finished': 37,\n",
       " 'the': 38,\n",
       " 'rest': 39,\n",
       " 'day': 40,\n",
       " 'working': 41,\n",
       " 'fine': 42,\n",
       " 'next': 43,\n",
       " 'when': 44,\n",
       " 'went': 45,\n",
       " 'into': 46,\n",
       " 'fired': 47,\n",
       " 'that': 48,\n",
       " 'situation': 49,\n",
       " 'one': 50,\n",
       " 'texas': 51,\n",
       " 'roadhouse': 52,\n",
       " 'because': 53,\n",
       " 'any': 54,\n",
       " 'could': 55,\n",
       " 'be': 56,\n",
       " 'their': 57,\n",
       " 'staff': 58,\n",
       " 'does': 59,\n",
       " 'not': 60,\n",
       " 'deserve': 61,\n",
       " 'my': 62,\n",
       " 'business': 63,\n",
       " 'yelp': 64,\n",
       " 'wants': 65,\n",
       " 'me': 66,\n",
       " 'give': 67,\n",
       " 'star': 68,\n",
       " 'but': 69,\n",
       " 'don': 70,\n",
       " 'believe': 71,\n",
       " 'it': 72,\n",
       " '': 73,\n",
       " 'hours': 74,\n",
       " 'minutes': 75,\n",
       " 'total': 76,\n",
       " 'time': 77,\n",
       " 'an': 78,\n",
       " 'extremely': 79,\n",
       " 'simple': 80,\n",
       " 'physical': 81,\n",
       " 'stay': 82,\n",
       " 'away': 83,\n",
       " 'unless': 84,\n",
       " 'you': 85,\n",
       " 'have': 86,\n",
       " 'waste': 87,\n",
       " 'less': 88,\n",
       " 'than': 89,\n",
       " 'stellar': 90,\n",
       " 'review': 91,\n",
       " 'is': 92,\n",
       " 'service': 93,\n",
       " 'we': 94,\n",
       " 'waited': 95,\n",
       " 'our': 96,\n",
       " 'meals': 97,\n",
       " 'delivered': 98,\n",
       " 'questioned': 99,\n",
       " 'waiter': 100,\n",
       " 'he': 101,\n",
       " 'was': 102,\n",
       " 'helpful': 103,\n",
       " 'so': 104,\n",
       " 'asked': 105,\n",
       " 'speak': 106,\n",
       " 'manager': 107,\n",
       " 'did': 108,\n",
       " 'even': 109,\n",
       " 'come': 110,\n",
       " 'with': 111,\n",
       " 'us': 112,\n",
       " 'were': 113,\n",
       " 'loyal': 114,\n",
       " 'neighborhood': 115,\n",
       " 'customers': 116,\n",
       " 'walking': 117,\n",
       " 'restaurant': 118,\n",
       " 'frequently': 119,\n",
       " 'husband': 120,\n",
       " 'then': 121,\n",
       " 'wrote': 122,\n",
       " 'email': 123,\n",
       " 'owner': 124,\n",
       " 'ignored': 125,\n",
       " 'by': 126,\n",
       " 'as': 127,\n",
       " 'well': 128,\n",
       " 'this': 129,\n",
       " 'obviously': 130,\n",
       " 'value': 131,\n",
       " 'customer': 132,\n",
       " 'very': 133,\n",
       " 'disappointed': 134,\n",
       " 'has': 135,\n",
       " 'lost': 136,\n",
       " 'regular': 137,\n",
       " 'm': 138,\n",
       " 's': 139,\n",
       " 'no': 140,\n",
       " 'way': 141,\n",
       " 'none': 142,\n",
       " 'n': 143,\n",
       " 'nas': 144,\n",
       " 'write': 145,\n",
       " 'door': 146,\n",
       " 'room': 147,\n",
       " 'open': 148,\n",
       " 'two': 149,\n",
       " 'gentlemen': 150,\n",
       " 'are': 151,\n",
       " 'checked': 152,\n",
       " 'going': 153,\n",
       " 'go': 154,\n",
       " 'on': 155,\n",
       " 'all': 156,\n",
       " 'evidently': 157,\n",
       " 'inn': 158,\n",
       " 'new': 159,\n",
       " 'lock': 160,\n",
       " 'system': 161,\n",
       " 'some': 162,\n",
       " 'reason': 163,\n",
       " 'impossible': 164,\n",
       " 'wait': 165,\n",
       " 'until': 166,\n",
       " 'out': 167,\n",
       " 'later': 168,\n",
       " 'today': 169,\n",
       " 'counting': 170,\n",
       " 'quiet': 171,\n",
       " 'd': 172,\n",
       " 'brought': 173,\n",
       " 'do': 174,\n",
       " 'now': 175,\n",
       " 'utterly': 176,\n",
       " 'stayed': 177,\n",
       " 'here': 178,\n",
       " 'once': 179,\n",
       " 'before': 180,\n",
       " 'loved': 181,\n",
       " 'lack': 182,\n",
       " 'concern': 183,\n",
       " 'respect': 184,\n",
       " 'sets': 185,\n",
       " 'low': 186,\n",
       " 'food': 187,\n",
       " 'mediocre': 188,\n",
       " 'at': 189,\n",
       " 'best': 190,\n",
       " 'after': 191,\n",
       " 'reading': 192,\n",
       " 'above': 193,\n",
       " 'positive': 194,\n",
       " 'reviews': 195,\n",
       " 'really': 196,\n",
       " 'great': 197,\n",
       " 'hence': 198,\n",
       " 'stars': 199,\n",
       " 'relleno': 200,\n",
       " 'soggy': 201,\n",
       " 'looked': 202,\n",
       " 'tasted': 203,\n",
       " 'like': 204,\n",
       " 'made': 205,\n",
       " 'factory': 206,\n",
       " 'guacamole': 207,\n",
       " 'decent': 208,\n",
       " 'didn': 209,\n",
       " 'care': 210,\n",
       " 'margarita': 211,\n",
       " 'mix': 212,\n",
       " 'nwe': 213,\n",
       " 'entertainment': 214,\n",
       " 'book': 215,\n",
       " 'pizza': 216,\n",
       " 'coupons': 217,\n",
       " 'came': 218,\n",
       " 'across': 219,\n",
       " 'domino': 220,\n",
       " 'twist': 221,\n",
       " 'fate': 222,\n",
       " 'since': 223,\n",
       " 'had': 224,\n",
       " 'easily': 225,\n",
       " 'pretty': 226,\n",
       " 'good': 227,\n",
       " 'coupon': 228,\n",
       " 'decided': 229,\n",
       " 'what': 230,\n",
       " 'seemed': 231,\n",
       " 'judgement': 232,\n",
       " 'would': 233,\n",
       " 'use': 234,\n",
       " 'shot': 235,\n",
       " 'nit': 236,\n",
       " 'will': 237,\n",
       " 'likely': 238,\n",
       " 'least': 239,\n",
       " 'try': 240,\n",
       " 'again': 241,\n",
       " 'npizza': 242,\n",
       " 'par': 243,\n",
       " 'those': 244,\n",
       " 'frozen': 245,\n",
       " 'ones': 246,\n",
       " 'from': 247,\n",
       " 'grocery': 248,\n",
       " 'store': 249,\n",
       " 'free': 250,\n",
       " 'sandwich': 251,\n",
       " 'shared': 252,\n",
       " 'tummy': 253,\n",
       " 'ndespite': 254,\n",
       " 'savings': 255,\n",
       " 'deal': 256,\n",
       " 'poor': 257,\n",
       " 'quality': 258,\n",
       " 'appointment': 259,\n",
       " 'months': 260,\n",
       " 'advance': 261,\n",
       " 'turned': 262,\n",
       " 'up': 263,\n",
       " 'told': 264,\n",
       " 'person': 265,\n",
       " 'quit': 266,\n",
       " 'weeks': 267,\n",
       " 'ago': 268,\n",
       " 'anyone': 269,\n",
       " 'available': 270,\n",
       " 'take': 271,\n",
       " 'attempt': 272,\n",
       " 'reschedule': 273,\n",
       " 'someone': 274,\n",
       " 'else': 275,\n",
       " 'or': 276,\n",
       " 'call': 277,\n",
       " 'cancel': 278,\n",
       " 'make': 279,\n",
       " 'things': 280,\n",
       " 'worse': 281,\n",
       " 'front': 282,\n",
       " 'desk': 283,\n",
       " 'such': 284,\n",
       " 'attitude': 285,\n",
       " 'tip': 286,\n",
       " 'beauty': 287,\n",
       " 'salon': 288,\n",
       " 'looks': 289,\n",
       " 'actually': 290,\n",
       " 'been': 291,\n",
       " 'rude': 292,\n",
       " 'women': 293,\n",
       " 'never': 294,\n",
       " 'back': 295,\n",
       " 'frankly': 296,\n",
       " 'get': 297,\n",
       " 'why': 298,\n",
       " 'people': 299,\n",
       " 'exception': 300,\n",
       " 'desert': 301,\n",
       " 'fruit': 302,\n",
       " 'cake': 303,\n",
       " 'dipped': 304,\n",
       " 'chocolate': 305,\n",
       " 'ok': 306,\n",
       " 'its': 307,\n",
       " 'alone': 308,\n",
       " 'nbut': 309,\n",
       " 'dinner': 310,\n",
       " 'overpriced': 311,\n",
       " 'overrated': 312,\n",
       " 'family': 313,\n",
       " 'friendly': 314,\n",
       " 'much': 315,\n",
       " 'better': 316,\n",
       " 'options': 317,\n",
       " 'terms': 318,\n",
       " 'thought': 319,\n",
       " 'nd': 320,\n",
       " 'chance': 321,\n",
       " 'bad': 322,\n",
       " 'idea': 323,\n",
       " 'employees': 324,\n",
       " 'feel': 325,\n",
       " 'your': 326,\n",
       " 'putting': 327,\n",
       " 'ordering': 328,\n",
       " 'if': 329,\n",
       " 'owners': 330,\n",
       " 'change': 331,\n",
       " 'quickly': 332,\n",
       " 'negative': 333,\n",
       " 'fried': 334,\n",
       " 'wontons': 335,\n",
       " 'stale': 336,\n",
       " 'awful': 337,\n",
       " 'kung': 338,\n",
       " 'pao': 339,\n",
       " 'chicken': 340,\n",
       " 'dry': 341,\n",
       " 'worth': 342,\n",
       " 'eating': 343,\n",
       " 'sun': 344,\n",
       " 'devil': 345,\n",
       " 'pork': 346,\n",
       " 'stringy': 347,\n",
       " 'filled': 348,\n",
       " 'gristle': 349,\n",
       " 'eat': 350,\n",
       " 'waitress': 351,\n",
       " 'how': 352,\n",
       " 'nothing': 353,\n",
       " 'b': 354,\n",
       " 'g': 355,\n",
       " 'refused': 356,\n",
       " 'yourself': 357,\n",
       " 'favor': 358,\n",
       " 'agree': 359,\n",
       " 'similar': 360,\n",
       " 'off': 361,\n",
       " 'bell': 362,\n",
       " 'mess': 363,\n",
       " 'stuff': 364,\n",
       " 'consignment': 365,\n",
       " 'credit': 366,\n",
       " 'return': 367,\n",
       " 'taken': 368,\n",
       " 'item': 369,\n",
       " 'big': 370,\n",
       " 'bags': 371,\n",
       " 'hardly': 372,\n",
       " 'used': 373,\n",
       " 'brand': 374,\n",
       " 'baby': 375,\n",
       " 'clothes': 376,\n",
       " 'ni': 377,\n",
       " 'bought': 378,\n",
       " 'several': 379,\n",
       " 'particular': 380,\n",
       " 'looking': 381,\n",
       " 'shoes': 382,\n",
       " 'filthy': 383,\n",
       " 'smell': 384,\n",
       " 'horrible': 385,\n",
       " 'toys': 386,\n",
       " 'missing': 387,\n",
       " 'parts': 388,\n",
       " 'grungy': 389,\n",
       " 'yet': 390,\n",
       " 'still': 391,\n",
       " 'greenway': 392,\n",
       " 'also': 393,\n",
       " 'witnessed': 394,\n",
       " 'area': 395,\n",
       " 'trash': 396,\n",
       " 'talking': 397,\n",
       " 'earlier': 398,\n",
       " 'conversation': 399,\n",
       " 'love': 400,\n",
       " 'shops': 401,\n",
       " 'kids': 402,\n",
       " 'mom': 403,\n",
       " 'learn': 404,\n",
       " 'buck': 405,\n",
       " 'stretch': 406,\n",
       " 'suggest': 407,\n",
       " 'upon': 408,\n",
       " 'child': 409,\n",
       " 'litchfield': 410,\n",
       " 'other': 411,\n",
       " 'mothers': 412,\n",
       " 'petsmart': 413,\n",
       " 'worst': 414,\n",
       " 'dog': 415,\n",
       " 'ntheir': 416,\n",
       " 'disgusting': 417,\n",
       " 'leave': 418,\n",
       " 'steel': 419,\n",
       " 'kennel': 420,\n",
       " 'themselves': 421,\n",
       " 'pay': 422,\n",
       " 'attention': 423,\n",
       " 'pup': 424,\n",
       " 'gave': 425,\n",
       " 'wrong': 426,\n",
       " 'medicine': 427,\n",
       " 'thousands': 428,\n",
       " 'vet': 429,\n",
       " 'stomach': 430,\n",
       " 'pumped': 431,\n",
       " 'trust': 432,\n",
       " 'dogs': 433,\n",
       " 'these': 434,\n",
       " 'crap': 435,\n",
       " 'shows': 436,\n",
       " 'overcharge': 437,\n",
       " 'most': 438,\n",
       " 'private': 439,\n",
       " 'places': 440,\n",
       " 'cheaper': 441,\n",
       " 'paying': 442,\n",
       " 'name': 443,\n",
       " 'having': 444,\n",
       " 'corporation': 445,\n",
       " 'behind': 446,\n",
       " 'doggie': 447,\n",
       " 'too': 448,\n",
       " 'check': 449,\n",
       " 'toss': 450,\n",
       " 'random': 451,\n",
       " 'stranger': 452,\n",
       " 'nthe': 453,\n",
       " 'grooming': 454,\n",
       " 'many': 455,\n",
       " 'screams': 456,\n",
       " 'groomers': 457,\n",
       " 'about': 458,\n",
       " 'taking': 459,\n",
       " 'either': 460,\n",
       " 'want': 461,\n",
       " 'money': 462,\n",
       " 'top': 463,\n",
       " 'package': 464,\n",
       " 'oatmeal': 465,\n",
       " 'cough': 466,\n",
       " 'bullshit': 467,\n",
       " 'shampoo': 468,\n",
       " 'lame': 469,\n",
       " 'teeth': 470,\n",
       " 'done': 471,\n",
       " 'salons': 472,\n",
       " 'vets': 473,\n",
       " 'offer': 474,\n",
       " 'services': 475,\n",
       " 'prices': 476,\n",
       " 'know': 477,\n",
       " 'tough': 478,\n",
       " 'economy': 479,\n",
       " 'important': 480,\n",
       " 'save': 481,\n",
       " 'bucks': 482,\n",
       " 'wherever': 483,\n",
       " 'whenever': 484,\n",
       " 'can': 485,\n",
       " 'every': 486,\n",
       " 'bother': 487,\n",
       " 'bring': 488,\n",
       " 'annoying': 489,\n",
       " 'll': 490,\n",
       " 'phone': 491,\n",
       " 'products': 492,\n",
       " 'items': 493,\n",
       " 'pet': 494,\n",
       " 'supply': 495,\n",
       " 'th': 496,\n",
       " 'mcdowell': 497,\n",
       " 'half': 498,\n",
       " 're': 499,\n",
       " 'something': 500,\n",
       " 'tell': 501,\n",
       " 'getting': 502,\n",
       " 'direct': 503,\n",
       " 'pee': 504,\n",
       " 'shelves': 505,\n",
       " 'stand': 506,\n",
       " 'around': 507,\n",
       " 'ignoring': 508,\n",
       " 'banfield': 509,\n",
       " 'joke': 510,\n",
       " 'wanted': 511,\n",
       " 'charge': 512,\n",
       " 'treat': 513,\n",
       " 'cats': 514,\n",
       " 'ear': 515,\n",
       " 'infection': 516,\n",
       " 'personal': 517,\n",
       " 'whatsoever': 518,\n",
       " 'shit': 519,\n",
       " 'nbottom': 520,\n",
       " 'line': 521,\n",
       " 'somewhere': 522,\n",
       " 'hundred': 523,\n",
       " 'times': 524,\n",
       " 'more': 525,\n",
       " 'professional': 526,\n",
       " 'pain': 527,\n",
       " 'dread': 528,\n",
       " 'each': 529,\n",
       " 'trip': 530,\n",
       " 'facility': 531,\n",
       " 'beat': 532,\n",
       " 'rugs': 533,\n",
       " 'stained': 534,\n",
       " 'wear': 535,\n",
       " 'flip': 536,\n",
       " 'flops': 537,\n",
       " 'towels': 538,\n",
       " 'need': 539,\n",
       " 'start': 540,\n",
       " 'first': 541,\n",
       " 'second': 542,\n",
       " 'washers': 543,\n",
       " 'expensive': 544,\n",
       " 've': 545,\n",
       " 'found': 546,\n",
       " 'city': 547,\n",
       " 'restrooms': 548,\n",
       " 'kind': 549,\n",
       " 'sends': 550,\n",
       " 'block': 551,\n",
       " 'down': 552,\n",
       " 'street': 553,\n",
       " 'coffee': 554,\n",
       " 'shop': 555,\n",
       " 'restroom': 556,\n",
       " 'last': 557,\n",
       " 'joint': 558,\n",
       " 'ate': 559,\n",
       " 'purchased': 560,\n",
       " 'groupon': 561,\n",
       " 'both': 562,\n",
       " 'enjoy': 563,\n",
       " 'greek': 564,\n",
       " 'excited': 565,\n",
       " 'lunch': 566,\n",
       " 'while': 567,\n",
       " 'definitely': 568,\n",
       " 'ordered': 569,\n",
       " 'falafel': 570,\n",
       " 'pita': 571,\n",
       " 'wasn': 572,\n",
       " 'enough': 573,\n",
       " 'help': 574,\n",
       " 'portions': 575,\n",
       " 'huge': 576,\n",
       " 'sort': 577,\n",
       " 'thing': 578,\n",
       " 'however': 579,\n",
       " 'am': 580,\n",
       " 'eater': 581,\n",
       " 'leftovers': 582,\n",
       " 'tend': 583,\n",
       " 'fridge': 584,\n",
       " 'particularly': 585,\n",
       " 'impressed': 586,\n",
       " 'nmy': 587,\n",
       " 'parmesan': 588,\n",
       " 'basically': 589,\n",
       " 'took': 590,\n",
       " 'breast': 591,\n",
       " 'threw': 592,\n",
       " 'marinara': 593,\n",
       " 'sauce': 594,\n",
       " 'little': 595,\n",
       " 'cheese': 596,\n",
       " 'served': 597,\n",
       " 'flavor': 598,\n",
       " 'seem': 599,\n",
       " 'marinated': 600,\n",
       " 'cooked': 601,\n",
       " 'interesting': 602,\n",
       " 'ton': 603,\n",
       " 'nthis': 604,\n",
       " 'enormous': 605,\n",
       " 'alright': 606,\n",
       " 'lobby': 607,\n",
       " 'nice': 608,\n",
       " 'weird': 609,\n",
       " 'under': 610,\n",
       " 'aaa': 611,\n",
       " 'government': 612,\n",
       " 'rate': 613,\n",
       " 'main': 614,\n",
       " 'ritz': 615,\n",
       " 'number': 616,\n",
       " 'literally': 617,\n",
       " 'car': 618,\n",
       " 'hotel': 619,\n",
       " 'bar': 620,\n",
       " 'common': 621,\n",
       " 'areas': 622,\n",
       " 'guests': 623,\n",
       " 'old': 624,\n",
       " 'drinks': 625,\n",
       " 'rooms': 626,\n",
       " 'vegas': 627,\n",
       " 'maybe': 628,\n",
       " 'should': 629,\n",
       " 'diagnosed': 630,\n",
       " 'dr': 631,\n",
       " 'austin': 632,\n",
       " 'always': 633,\n",
       " 'hour': 634,\n",
       " 'keep': 635,\n",
       " 'calling': 636,\n",
       " 'office': 637,\n",
       " 'results': 638,\n",
       " 'favorite': 639,\n",
       " 'ulta': 640,\n",
       " 'locations': 641,\n",
       " 'apparently': 642,\n",
       " 'general': 643,\n",
       " 'running': 644,\n",
       " 'registers': 645,\n",
       " 'tonight': 646,\n",
       " 'sure': 647,\n",
       " 'wouldn': 648,\n",
       " 'writing': 649,\n",
       " 'sooooo': 650,\n",
       " 'say': 651,\n",
       " 'hello': 652,\n",
       " 'called': 653,\n",
       " 'register': 654,\n",
       " 'st': 655,\n",
       " 'began': 656,\n",
       " 'ring': 657,\n",
       " 'pulled': 658,\n",
       " 'ultra': 659,\n",
       " 'card': 660,\n",
       " 'needed': 661,\n",
       " 'put': 662,\n",
       " 'walked': 663,\n",
       " 'seriously': 664,\n",
       " 'might': 665,\n",
       " 'holidays': 666,\n",
       " 'helping': 667,\n",
       " 'public': 668,\n",
       " 'think': 669,\n",
       " 'drive': 670,\n",
       " 'further': 671,\n",
       " 'chandler': 672,\n",
       " 'westin': 673,\n",
       " 'chain': 674,\n",
       " 'thus': 675,\n",
       " 'expectations': 676,\n",
       " 'case': 677,\n",
       " 'met': 678,\n",
       " 'comfortable': 679,\n",
       " 'beds': 680,\n",
       " 'unfriendly': 681,\n",
       " 'appealing': 682,\n",
       " 'double': 683,\n",
       " 'shower': 684,\n",
       " 'head': 685,\n",
       " 'nnow': 686,\n",
       " 'reasons': 687,\n",
       " 'fails': 688,\n",
       " 'relatively': 689,\n",
       " 'choice': 690,\n",
       " 'examples': 691,\n",
       " 'omelet': 692,\n",
       " 'greasy': 693,\n",
       " 'tasteless': 694,\n",
       " 'canned': 695,\n",
       " 'mushrooms': 696,\n",
       " 'breakfast': 697,\n",
       " 'buffet': 698,\n",
       " 'got': 699,\n",
       " 'typically': 700,\n",
       " 'become': 701,\n",
       " 'lukewarm': 702,\n",
       " 'choices': 703,\n",
       " 'salty': 704,\n",
       " 'e': 705,\n",
       " 'salad': 706,\n",
       " 'sandwiches': 707,\n",
       " 'burgers': 708,\n",
       " 'pancakes': 709,\n",
       " 'excellent': 710,\n",
       " 'nor': 711,\n",
       " 'hyatt': 712,\n",
       " 'location': 713,\n",
       " 'omni': 714,\n",
       " 'comparable': 715,\n",
       " 'hotels': 716,\n",
       " 'restaurants': 717,\n",
       " 'shopping': 718,\n",
       " 'attractions': 719,\n",
       " 'blocks': 720,\n",
       " 'anywhere': 721,\n",
       " 'pharmacy': 722,\n",
       " 'concierge': 723,\n",
       " 'suggestion': 724,\n",
       " 'housekeeping': 725,\n",
       " 'seems': 726,\n",
       " 'only': 727,\n",
       " 'quite': 728,\n",
       " 'vacuum': 729,\n",
       " 'cracker': 730,\n",
       " 'crumbs': 731,\n",
       " 'spilled': 732,\n",
       " 'days': 733,\n",
       " 'forget': 734,\n",
       " 'essential': 735,\n",
       " 'soap': 736,\n",
       " 'nif': 737,\n",
       " 'cheap': 738,\n",
       " 'sub': 739,\n",
       " 'per': 740,\n",
       " 'night': 741,\n",
       " 'manage': 742,\n",
       " 'charlotte': 743,\n",
       " 'terribly': 744,\n",
       " 'demand': 745,\n",
       " 'spotless': 746,\n",
       " 'sexy': 747,\n",
       " 'charming': 748,\n",
       " 'neither': 749,\n",
       " 'gas': 750,\n",
       " 'high': 751,\n",
       " 'due': 752,\n",
       " 'lake': 753,\n",
       " 'proximity': 754,\n",
       " 'being': 755,\n",
       " 'station': 756,\n",
       " 'town': 757,\n",
       " 'desperate': 758,\n",
       " 'building': 759,\n",
       " 'gary': 760,\n",
       " 'anymore': 761,\n",
       " 'same': 762,\n",
       " 'dish': 763,\n",
       " 'sometimes': 764,\n",
       " 'plate': 765,\n",
       " 'depends': 766,\n",
       " 'kitchen': 767,\n",
       " 'sales': 768,\n",
       " 'listen': 769,\n",
       " 'anything': 770,\n",
       " 'printed': 771,\n",
       " 'pictures': 772,\n",
       " 'dresses': 773,\n",
       " 'styles': 774,\n",
       " 'liked': 775,\n",
       " 'dress': 776,\n",
       " 'genuinely': 777,\n",
       " 'sorry': 778,\n",
       " 'carry': 779,\n",
       " 'size': 780,\n",
       " 'overall': 781,\n",
       " 'especially': 782,\n",
       " 'won': 783,\n",
       " 'ghetto': 784,\n",
       " 'almost': 785,\n",
       " 'walmart': 786,\n",
       " 'right': 787,\n",
       " 'base': 788,\n",
       " 'long': 789,\n",
       " 'cashiers': 790,\n",
       " 'organized': 791,\n",
       " 'constantly': 792,\n",
       " 'wandering': 793,\n",
       " 'trying': 794,\n",
       " 'rather': 795,\n",
       " 'target': 796,\n",
       " 'cause': 797,\n",
       " 'ask': 798,\n",
       " 'myself': 799,\n",
       " 'edible': 800,\n",
       " 'five': 801,\n",
       " 'dollars': 802,\n",
       " 'tortilla': 803,\n",
       " 'chips': 804,\n",
       " 'homemade': 805,\n",
       " 'salsa': 806,\n",
       " 'clearly': 807,\n",
       " 'wings': 808,\n",
       " 'fake': 809,\n",
       " 'butter': 810,\n",
       " 'rubber': 811,\n",
       " 'fault': 812,\n",
       " 'guess': 813,\n",
       " 'four': 814,\n",
       " 'pad': 815,\n",
       " 'se': 816,\n",
       " 'thai': 817,\n",
       " 'stir': 818,\n",
       " 'sweet': 819,\n",
       " 'basil': 820,\n",
       " 'sides': 821,\n",
       " 'steamed': 822,\n",
       " 'sticky': 823,\n",
       " 'rice': 824,\n",
       " 'probably': 825,\n",
       " 'recommend': 826,\n",
       " 'representation': 827,\n",
       " 'heat': 828,\n",
       " 'ours': 829,\n",
       " 'level': 830,\n",
       " 'order': 831,\n",
       " 'known': 832,\n",
       " 'usually': 833,\n",
       " 'mild': 834,\n",
       " 'medium': 835,\n",
       " 'spicy': 836,\n",
       " 'hot': 837,\n",
       " 'veggies': 838,\n",
       " 'crisp': 839,\n",
       " 'noodles': 840,\n",
       " 'egg': 841,\n",
       " 'suggests': 842,\n",
       " 'means': 843,\n",
       " 'hut': 844,\n",
       " 'ever': 845,\n",
       " 'happy': 846,\n",
       " 'tried': 847,\n",
       " 'mia': 848,\n",
       " 'march': 849,\n",
       " 'mistake': 850,\n",
       " 'life': 851,\n",
       " 'crust': 852,\n",
       " 'pepperoni': 853,\n",
       " 'complain': 854,\n",
       " 'website': 855,\n",
       " 'let': 856,\n",
       " 'equipment': 857,\n",
       " 'dirty': 858,\n",
       " 'nok': 859,\n",
       " 'forgot': 860,\n",
       " 'weekend': 861,\n",
       " 'different': 862,\n",
       " 'sale': 863,\n",
       " 'nbig': 864,\n",
       " 'problems': 865,\n",
       " 'kid': 866,\n",
       " 'saw': 867,\n",
       " 'info': 868,\n",
       " 'complained': 869,\n",
       " 'nso': 870,\n",
       " 'apologized': 871,\n",
       " 'na': 872,\n",
       " 'lady': 873,\n",
       " 'nshe': 874,\n",
       " 'sound': 875,\n",
       " 'shocked': 876,\n",
       " 'pizzas': 877,\n",
       " 'using': 878,\n",
       " 'lesser': 879,\n",
       " 'ingredients': 880,\n",
       " 'nno': 881,\n",
       " 'exact': 882,\n",
       " 'words': 883,\n",
       " 'neven': 884,\n",
       " 'thanks': 885,\n",
       " 'end': 886,\n",
       " 'past': 887,\n",
       " 'sticks': 888,\n",
       " 'experiences': 889,\n",
       " 'few': 890,\n",
       " 'ruined': 891,\n",
       " 'falling': 892,\n",
       " 'zero': 893,\n",
       " 'couple': 894,\n",
       " 'tea': 895,\n",
       " 'bread': 896,\n",
       " 'barely': 897,\n",
       " 'warm': 898,\n",
       " 'squash': 899,\n",
       " 'tortellini': 900,\n",
       " 'crispy': 901,\n",
       " 'prosciutto': 902,\n",
       " 'butternut': 903,\n",
       " 'cut': 904,\n",
       " 'nanother': 905,\n",
       " 'shrimp': 906,\n",
       " 'pasta': 907,\n",
       " 'bland': 908,\n",
       " 'adding': 909,\n",
       " 'salt': 910,\n",
       " 'pepper': 911,\n",
       " 'nwill': 912,\n",
       " 'look': 913,\n",
       " 'expect': 914,\n",
       " 'whole': 915,\n",
       " 'lot': 916,\n",
       " 'albertson': 917,\n",
       " 'mega': 918,\n",
       " 'buy': 919,\n",
       " 'month': 920,\n",
       " 'became': 921,\n",
       " 'aware': 922,\n",
       " 'carried': 923,\n",
       " 'local': 924,\n",
       " 'support': 925,\n",
       " 'badly': 926,\n",
       " 'feeling': 927,\n",
       " 'playing': 928,\n",
       " 'online': 929,\n",
       " 'blue': 930,\n",
       " 'oasis': 931,\n",
       " 'surprise': 932,\n",
       " 'company': 933,\n",
       " 'las': 934,\n",
       " 'farms': 935,\n",
       " 'surprising': 936,\n",
       " 'home': 937,\n",
       " 'san': 938,\n",
       " 'francisco': 939,\n",
       " 'fresh': 940,\n",
       " 'walk': 941,\n",
       " 'nfirst': 942,\n",
       " 'doesn': 943,\n",
       " 'sell': 944,\n",
       " 'isn': 945,\n",
       " 'worker': 946,\n",
       " 'counter': 947,\n",
       " 'offered': 948,\n",
       " 'fact': 949,\n",
       " 'heads': 950,\n",
       " 'disappointing': 951,\n",
       " 'boyfriend': 952,\n",
       " 'week': 953,\n",
       " 'pound': 954,\n",
       " 'note': 955,\n",
       " 'spent': 956,\n",
       " 'groceries': 957,\n",
       " 'otherwise': 958,\n",
       " 'department': 959,\n",
       " 'urge': 960,\n",
       " 'continue': 961,\n",
       " 'selling': 962,\n",
       " 'product': 963,\n",
       " 'rewarded': 964,\n",
       " 'impersonal': 965,\n",
       " 'response': 966,\n",
       " 'written': 967,\n",
       " 'read': 968,\n",
       " 'letter': 969,\n",
       " 'ntoday': 970,\n",
       " 'usual': 971,\n",
       " 'noticed': 972,\n",
       " 'display': 973,\n",
       " 'longer': 974,\n",
       " 'immediately': 975,\n",
       " 'clear': 976,\n",
       " 'buying': 977,\n",
       " 'arrival': 978,\n",
       " 'purpose': 979,\n",
       " 'insulting': 980,\n",
       " 'continued': 981,\n",
       " 'full': 982,\n",
       " 'price': 983,\n",
       " 'compare': 984,\n",
       " 'shipped': 985,\n",
       " 'thailand': 986,\n",
       " 'miles': 987,\n",
       " 'road': 988,\n",
       " 'promptly': 989,\n",
       " 'wonder': 990,\n",
       " 'expects': 991,\n",
       " 'sitting': 992,\n",
       " 'freezer': 993,\n",
       " 'displayed': 994,\n",
       " 'nagain': 995,\n",
       " 'realize': 996,\n",
       " 'aren': 997,\n",
       " 'may': 998,\n",
       " 'worried': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['t_2_i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookUpToken('terrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'terrible'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookUpIndex(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0f2a156638663e52e3310a5b94cba9f1aaa2c6363cff10141cd0a597f3d9860"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6rc1 64-bit ('nltk': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
