{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence : I left my phone on the left side of the room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(\"I left my phone on the left side of the room.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('left', 'VBD'), ('my', 'PRP$'), ('phone', 'NN'), ('on', 'IN'), ('the', 'DT'), ('left', 'JJ'), ('side', 'NN'), ('of', 'IN'), ('the', 'DT'), ('room', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_text = nltk.pos_tag(text)\n",
    "print(tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = nltk.RegexpParser(grammar)\n",
    "chunked_text = chunker.parse(tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  left/VBD\n",
      "  my/PRP$\n",
      "  (NP phone/NN)\n",
      "  on/IN\n",
      "  (NP the/DT left/JJ side/NN)\n",
      "  of/IN\n",
      "  (NP the/DT room/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# 청킹 (Chunking) => 토큰 (token)을 가지고 구(pharase)를 만드는 것\n",
    "# 만들어진 구(pharase) => chunk라고 함!\n",
    "# NP : Noun Pharase (명사구)\n",
    "\n",
    "print(chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(\"the left side\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('left', 'JJ'), ('side', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tagged_text = nltk.pos_tag(text)\n",
    "print(tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1 :  (S the/DT left/JJ side/NN)\n"
     ]
    }
   ],
   "source": [
    "# Chinking Case 1 : 일치하는 토큰 시퀀스가 전체 청크를 구성하는 경우 전체 청크가 제거\n",
    "\n",
    "grammar1 = \"\"\"NP: {<.*>+}\n",
    "               }<DT|JJ|NN>+{\"\"\"\n",
    "\n",
    "chunker = nltk.RegexpParser(grammar1)\n",
    "chunked_text1 = chunker.parse(tagged_text)\n",
    "print(\"Case 1 : \", chunked_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 :  (S (NP the/DT) left/JJ (NP side/NN))\n"
     ]
    }
   ],
   "source": [
    "# Chinking Case 2 : 토큰 시퀀스가 청크 중간에 나타나면 해당 토큰를 제거\n",
    "# {<.*>+} : chunk 전체\n",
    "# }<JJ>+{ : 우리가 chunk에서 제거할 부분을 정의\n",
    "\n",
    "\n",
    "grammar2 = \"\"\"NP: {<.*>+} \n",
    "               }<JJ>+{\"\"\"\n",
    "\n",
    "chunker = nltk.RegexpParser(grammar2)\n",
    "chunked_text2 = chunker.parse(tagged_text)\n",
    "print(\"Case 2 : \", chunked_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 3 :  (S the/DT left/JJ (NP side/NN))\n"
     ]
    }
   ],
   "source": [
    "# Chinking Case 3 : 마지막 것을 제외하고 다 제거하겠다.\n",
    "\n",
    "grammar3 = \"\"\"NP: {<.*>+}\n",
    "               }<DT|JJ>+{\"\"\"\n",
    "\n",
    "chunker = nltk.RegexpParser(grammar3)\n",
    "chunked_text3 = chunker.parse(tagged_text)\n",
    "print(\"Case 3 : \", chunked_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'PRP'), (\"'s\", 'VBZ'), ('got', 'VBD'), ('to', 'TO'), ('polish', 'VB'), ('up', 'RP'), ('his', 'PRP$'), ('Polish', 'NN'), ('for', 'IN'), ('his', 'PRP$'), ('job', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"He's got to polish up his Polish for his job.\")\n",
    "tagged_text = nltk.pos_tag(text)\n",
    "print(tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  He/PRP\n",
      "  's/VBZ\n",
      "  got/VBD\n",
      "  to/TO\n",
      "  polish/VB\n",
      "  up/RP\n",
      "  his/PRP$\n",
      "  (GPE Polish/NN)\n",
      "  for/IN\n",
      "  his/PRP$\n",
      "  job/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "namedEntity = nltk.ne_chunk(tagged_text)\n",
    "print(namedEntity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac8013a75859c6925308985c5e1ee5242e6e6f0429f283ee420b8cff3c2914b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv_night': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
